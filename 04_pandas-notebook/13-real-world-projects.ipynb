{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 13: Real-World Projects (Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on making it through all the levels! You've learned the core concepts of Pandas, from the basics of DataFrames to advanced topics like time series and performance optimization.\n",
    "\n",
    "The absolute best way to solidify these skills and become a proficient Pandas user is to apply them to real-world datasets. This final notebook provides ideas for projects and points you to resources where you can find interesting data to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some ideas for projects. For each one, try to follow the full data analysis workflow: **Load -> Clean -> Transform -> Aggregate -> Visualize**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sales Data Analysis\n",
    "- **Goal:** Analyze sales data to find top-selling products, identify regional performance, and visualize monthly sales trends.\n",
    "- **Skills Used:** `read_csv`, `to_datetime`, `groupby`, `agg`, `sort_values`, `.dt` accessor, plotting.\n",
    "- **Potential Dataset:** [Superstore Sales Dataset on Kaggle](https://www.kaggle.com/datasets/rohitsahoo/sales-forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Log File Processing\n",
    "- **Goal:** Parse web server logs to find the most frequent IP addresses, count 404 errors, and determine peak traffic hours.\n",
    "- **Skills Used:** `read_csv` (with custom separators), string methods (`.str.extract`), `to_datetime`, `groupby`, `value_counts`.\n",
    "- **Potential Dataset:** You can find sample Apache log files online or generate your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Survey Data Cleanup\n",
    "- **Goal:** Clean a messy survey dataset by handling missing responses, converting categorical answers to numerical codes, and analyzing demographic breakdowns.\n",
    "- **Skills Used:** `isna`, `fillna`, `dropna`, `map`, `astype`, `pd.get_dummies`, `crosstab`.\n",
    "- **Potential Dataset:** [Kaggle Developer Survey](https://www.kaggle.com/datasets/kaggle/kaggle-survey-2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stock Price Analysis\n",
    "- **Goal:** Analyze historical stock data (Open, High, Low, Close) to calculate daily returns, 30-day moving averages, and volatility.\n",
    "- **Skills Used:** `read_csv`, `to_datetime`, `set_index`, `shift`, `rolling`, plotting.\n",
    "- **Potential Dataset:** You can download historical data from Yahoo Finance or use a library like `yfinance`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Web Scraping + Pandas\n",
    "- **Goal:** Scrape a table from a website (e.g., a list of tallest buildings from Wikipedia), load it into a DataFrame, clean it up, and perform analysis.\n",
    "- **Skills Used:** A scraping library like `BeautifulSoup` or `requests`, `pd.read_html`, string methods, `astype`.\n",
    "- **Potential Project:** Scrape the \"List of largest companies by revenue\" page on Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Resources for Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[Kaggle Datasets](https://www.kaggle.com/datasets):** A huge collection of datasets on almost any topic imaginable.\n",
    "- **[Data.gov](https://data.gov/):** The home of the U.S. Government’s open data.\n",
    "- **[Awesome Public Datasets on GitHub](https://github.com/awesomedata/awesome-public-datasets):** A curated list of high-quality public datasets.\n",
    "- **[Google Dataset Search](https://datasetsearch.research.google.com/):** A search engine for datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Learning Path Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this journey, you have learned to:\n",
    "\n",
    "✅ **Install & load data:** Get data from files like CSV, Excel, and JSON into a DataFrame.\n",
    "✅ **Explore DataFrame basics:** Understand Series and DataFrames, and use attributes like `.shape`, `.info()`, and `.describe()`.\n",
    "✅ **Select & filter data:** Use `.loc`, `.iloc`, boolean indexing, and `.query()` to access specific parts of your data.\n",
    "✅ **Handle missing values & strings:** Clean your data using methods for handling NaNs, duplicates, data types, and string manipulation.\n",
    "✅ **Group, aggregate, & pivot:** Summarize your data using `groupby`, `pivot_table`, and `crosstab`.\n",
    "✅ **Merge & reshape:** Combine and restructure data with `concat`, `merge`, `melt`, and `pivot`.\n",
    "✅ **Work with dates:** Master time series data with `to_datetime`, `DateTimeIndex`, resampling, and rolling windows.\n",
    "✅ **Optimize performance:** Write faster, more memory-efficient code.\n",
    "✅ **Build end-to-end projects:** Apply your skills to solve real-world problems.\n",
    "✅ **Master method chaining & pipelines:** Write clean, reusable, and professional-grade code with `.pipe()`.\n",
    "\n",
    "**Keep practicing, and happy coding!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
