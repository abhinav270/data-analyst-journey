{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 11: Performance & Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your datasets grow, performance becomes increasingly important. Writing efficient Pandas code can save you time and memory. This level covers techniques to make your data manipulation faster and more memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Memory Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `category` dtype\n",
    "If you have a column with a limited number of repeated string values (e.g., country, department), converting it to the `category` dtype can save a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with object dtype: 63.75 MB\n",
      "Memory usage with category dtype: 1.00 MB\n"
     ]
    }
   ],
   "source": [
    "size = 1_000_000\n",
    "departments = ['HR', 'Engineering', 'Sales', 'Marketing']\n",
    "df = pd.DataFrame({\n",
    "    'department': np.random.choice(departments, size=size)\n",
    "})\n",
    "\n",
    "print(f\"Memory usage with object dtype: {df['department'].memory_usage(deep=True) / 1e6:.2f} MB\")\n",
    "\n",
    "df['department'] = df['department'].astype('category')\n",
    "print(f\"Memory usage with category dtype: {df['department'].memory_usage(deep=True) / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downcasting Numeric Types\n",
    "If your numeric data fits into a smaller integer or float type (e.g., `int8` instead of `int64`), you can downcast it to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original memory usage: 4.00 MB\n",
      "Downcasted memory usage: 1.00 MB\n",
      "New dtype: int8\n"
     ]
    }
   ],
   "source": [
    "df_num = pd.DataFrame({'a': np.random.randint(0, 100, size=size)})\n",
    "print(f\"Original memory usage: {df_num['a'].memory_usage(deep=True) / 1e6:.2f} MB\")\n",
    "\n",
    "# pd.to_numeric can downcast automatically\n",
    "df_num['a_downcast'] = pd.to_numeric(df_num['a'], downcast='integer')\n",
    "print(f\"Downcasted memory usage: {df_num['a_downcast'].memory_usage(deep=True) / 1e6:.2f} MB\")\n",
    "print(f\"New dtype: {df_num['a_downcast'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization is the practice of applying operations to whole arrays instead of iterating over them element by element. Pandas operations are vectorized, meaning they are much faster than using Python loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 ms ± 9.25 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "103 μs ± 5.89 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "df_perf = pd.DataFrame(np.random.rand(10000, 3), columns=['A', 'B', 'C'])\n",
    "\n",
    "# Inefficient: Using a loop\n",
    "def custom_sum_loop(df):\n",
    "    total = 0\n",
    "    for i in range(len(df)):\n",
    "        total += df['A'][i] + df['B'][i]\n",
    "    return total\n",
    "\n",
    "# Efficient: Vectorized operation\n",
    "def custom_sum_vectorized(df):\n",
    "    return (df['A'] + df['B']).sum()\n",
    "\n",
    "%timeit custom_sum_loop(df_perf)\n",
    "%timeit custom_sum_vectorized(df_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.where()`, `.mask()`, `.clip()`\n",
    "These are vectorized alternatives to `if/else` logic.\n",
    "- **`.where(cond, other)`**: Where `cond` is `True`, keep the original value. Otherwise, replace with `other`.\n",
    "- **`.mask(cond, other)`**: Where `cond` is `True`, replace with `other`. Otherwise, keep the original value. (Opposite of `where`)\n",
    "- **`.clip(lower, upper)`**: Trim values at specified lower and/or upper bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1   -1\n",
       "2   -1\n",
       "3    3\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(range(5))\n",
    "# Replace values less than 3 with -1\n",
    "s.where(s >= 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     1\n",
       "2     2\n",
       "3    10\n",
       "4    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace values greater than 2 with 10\n",
    "s.mask(s > 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clip values to be between 1 and 3\n",
    "s.clip(1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Method Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method chaining is a style of programming where you call methods on an object one after another. This can lead to clean, readable code by avoiding the creation of intermediate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_chain \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdata\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Without chaining\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df_chain\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "df_chain = pd.DataFrame(data)\n",
    "\n",
    "# Without chaining\n",
    "df1 = df_chain.dropna()\n",
    "df2 = df1.query('Salary > 80000')\n",
    "df3 = df2.assign(Salary_k = df2['Salary'] / 1000)\n",
    "result = df3[['Employee', 'Salary_k']]\n",
    "\n",
    "# With method chaining\n",
    "result_chained = (\n",
    "    df_chain\n",
    "    .dropna()\n",
    "    .query('Salary > 80000')\n",
    "    .assign(Salary_k = lambda df: df['Salary'] / 1000)\n",
    "    [['Employee', 'Salary_k']]\n",
    ")\n",
    "\n",
    "result_chained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Using `eval()` and `query()` for Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large DataFrames, `pd.eval()` and `df.query()` can be faster than standard Python expressions because they use the `numexpr` library in the background, which can perform operations more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install numexpr: !pip install numexpr\n",
    "df_large = pd.DataFrame(np.random.rand(1_000_000, 4), columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "%timeit df_large['A'] + df_large['B'] > 0.5\n",
    "%timeit pd.eval(\"df_large['A'] + df_large['B'] > 0.5\")\n",
    "%timeit df_large.query(\"A + B > 0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 When to Use Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Pandas is incredibly powerful, it's not always the best tool for every job, especially with very large datasets (that don't fit in memory).\n",
    "\n",
    "### Modin\n",
    "- **What it is:** A library that wraps Pandas and parallelizes its operations across all available CPU cores.\n",
    "- **When to use:** When your dataset is large (e.g., 1GB+) and your operations are taking too long. It has a nearly identical API to Pandas, so changes are minimal (`import modin.pandas as pd`).\n",
    "\n",
    "### Polars\n",
    "- **What it is:** A completely separate DataFrame library built from the ground up in Rust. It's known for its speed and memory efficiency.\n",
    "- **When to use:** When you need the absolute best performance, especially for large datasets and complex queries. It has its own distinct API that you would need to learn, but it is often significantly faster than Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
