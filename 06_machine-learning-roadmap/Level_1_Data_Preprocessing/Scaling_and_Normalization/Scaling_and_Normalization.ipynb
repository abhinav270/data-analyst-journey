{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.3: Scaling & Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is a critical preprocessing step. Many machine learning algorithms (like SVMs, Logistic Regression, and Neural Networks) perform better or converge faster when features are on a relatively similar scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = {\n",
    "    'age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 100], # includes outlier\n",
    "    'salary': [50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 250000] # includes outlier\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# IMPORTANT: Split data first to prevent data leakage\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Practice**: Always fit your scaler on the training data and then use it to transform both the training and the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization (Z-score Scaling)\n",
    "Rescales features to have a mean (μ) of 0 and a standard deviation (σ) of 1. Formula: `(x - μ) / σ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler - Mean of transformed train data: [2.77555756e-17 0.00000000e+00]\n",
      "StandardScaler - Std Dev of transformed train data: [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler_std = StandardScaler()\n",
    "X_train_std = scaler_std.fit_transform(X_train)\n",
    "X_test_std = scaler_std.transform(X_test)\n",
    "\n",
    "print(\"StandardScaler - Mean of transformed train data:\", X_train_std.mean(axis=0))\n",
    "print(\"StandardScaler - Std Dev of transformed train data:\", X_train_std.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling\n",
    "Rescales features to a fixed range, usually [0, 1]. Formula: `(x - min) / (max - min)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler - Min of transformed train data: [0. 0.]\n",
      "MinMaxScaler - Max of transformed train data: [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler_minmax = MinMaxScaler()\n",
    "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
    "X_test_minmax = scaler_minmax.transform(X_test)\n",
    "\n",
    "print(\"MinMaxScaler - Min of transformed train data:\", X_train_minmax.min(axis=0))\n",
    "print(\"MinMaxScaler - Max of transformed train data:\", X_train_minmax.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaling\n",
    "Uses statistics that are robust to outliers (median and Interquartile Range - IQR). Formula: `(x - median) / IQR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Data:\n",
      "    age  salary\n",
      "5   50  100000\n",
      "0   25   50000\n",
      "7   60  120000\n",
      "2   35   70000\n",
      "9  100  250000\n",
      "4   45   90000\n",
      "3   40   80000\n",
      "6   55  110000\n",
      "\n",
      "Robust Scaler Transformed Training Data:\n",
      "         age    salary\n",
      "0  0.142857  0.142857\n",
      "1 -1.285714 -1.285714\n",
      "2  0.714286  0.714286\n",
      "3 -0.714286 -0.714286\n",
      "4  3.000000  4.428571\n",
      "5 -0.142857 -0.142857\n",
      "6 -0.428571 -0.428571\n",
      "7  0.428571  0.428571\n"
     ]
    }
   ],
   "source": [
    "scaler_robust = RobustScaler()\n",
    "X_train_robust = scaler_robust.fit_transform(X_train)\n",
    "X_test_robust = scaler_robust.transform(X_test)\n",
    "\n",
    "print(\"Original Training Data:\\n\", X_train)\n",
    "print(\"\\nRobust Scaler Transformed Training Data:\\n\", pd.DataFrame(X_train_robust, columns=X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Normalization scales individual samples (rows) to have unit norm (length of 1). It is used when the direction of the data matters, not the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original first row: [    50 100000]\n",
      "Normalized first row: [4.99999938e-04 9.99999875e-01]\n",
      "L2 Norm of first row: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(norm='l2')\n",
    "X_train_normalized = normalizer.fit_transform(X_train)\n",
    "\n",
    "print(\"Original first row:\", X_train.iloc[0].values)\n",
    "print(\"Normalized first row:\", X_train_normalized[0])\n",
    "print(\"L2 Norm of first row:\", np.linalg.norm(X_train_normalized[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
