{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.4: Model Selection - Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn `Pipeline`s are a powerful tool for chaining together multiple data processing steps (transformers) and a final estimator (like a classifier or regressor). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Pipelines?\n",
    "1.  **Convenience**: You only have to call `fit` and `predict` once on your data to fit a whole sequence of steps.\n",
    "2.  **Preventing Data Leakage**: This is the most important reason. When using tools like `GridSearchCV`, a pipeline ensures that preprocessing steps (like scaling) are applied correctly *within each fold* of the cross-validation. This prevents information from the validation fold from 'leaking' into the training process, giving you a more reliable evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Simple Pipeline\n",
    "A pipeline is a list of (name, transformer/estimator) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline score on test data: 1.0000\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),        # Step 1: Scale the data\n",
    "    ('svc', SVC(random_state=42))      # Step 2: Apply the classifier\n",
    "])\n",
    "\n",
    "# Now we can treat the whole pipeline as a single estimator\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Pipeline score on test data: {pipe.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pipelines with GridSearchCV\n",
    "This is where pipelines truly shine. We can tune the hyperparameters of any step in the pipeline. The parameter names are created by joining the step name and the parameter name with a double underscore `__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for the pipeline: {'svc__C': 100, 'svc__gamma': 0.01}\n",
      "Best cross-validation score: 0.9667\n",
      "\n",
      "Final score on test set: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# We can tune the SVM's C and gamma parameters\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for the pipeline:\", search.best_params_)\n",
    "print(f\"Best cross-validation score: {search.best_score_:.4f}\")\n",
    "print(f\"\\nFinal score on test set: {search.score(X_test, y_test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
