{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.8: Unsupervised Learning - Association Rule Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association Rule Learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. The classic example is **Market Basket Analysis**, where a supermarket might want to find out which items are frequently purchased together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Goal: Find Rules\n",
    "The goal is to find rules of the form: **If {A} then {B}**.\n",
    "For example: **If {Diapers} then {Beer}**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Metrics\n",
    "To determine if a rule is 'interesting', we use three key metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Support\n",
    "The popularity of an itemset. It's the fraction of transactions that contain the itemset.\n",
    "\n",
    "`Support(A) = (Number of transactions containing A) / (Total number of transactions)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Confidence\n",
    "The likelihood of seeing itemset {B} in a transaction that also contains {A}. It's a measure of the rule's predictive power.\n",
    "\n",
    "`Confidence(A -> B) = Support(A U B) / Support(A)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Lift\n",
    "The increase in the ratio of the sale of {B} when {A} is sold. It tells us how much more likely item {B} is to be purchased when item {A} is purchased, compared to its overall popularity.\n",
    "\n",
    "`Lift(A -> B) = Confidence(A -> B) / Support(B)`\n",
    "\n",
    "- **Lift = 1**: No association.\n",
    "- **Lift > 1**: Positive correlation (items are likely to be bought together).\n",
    "- **Lift < 1**: Negative correlation (items are unlikely to be bought together)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Apriori Algorithm\n",
    "The Apriori algorithm is the most well-known algorithm for association rule mining. It uses a 'bottom-up' approach, where frequent itemsets are extended one item at a time (a step known as candidate generation), and groups of candidates are tested against the data. The algorithm terminates when no further successful extensions are found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "While you can implement the logic with Pandas, specialized libraries are much more efficient.\n",
    "\n",
    "- **`mlxtend`**: The most common and straightforward library for association rule mining in Python.\n",
    "\n",
    "A full implementation is beyond the scope of this core scikit-learn roadmap, but it's a valuable technique to be aware of, especially in retail and e-commerce analytics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
